\documentclass[12pt, titlepage]{article}

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=red,
    urlcolor=blue
}
\usepackage[round]{natbib}
\usepackage{longtable}
\input{../Comments}
\input{../Common}

\begin{document}

\title{Verification and Validation Report: \progname} 
\author{\authname}
\date{\today}
	
\maketitle

\pagenumbering{roman}

\section{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
Date 1 & 1.0 & Notes\\
Date 2 & 1.1 & Notes\\
\bottomrule
\end{tabularx}

~\newpage

\section{Symbols, Abbreviations and Acronyms}


Refer to Section 1.3 of the
\href{https://github.com/PlutosCapstone/Plutos/blob/main/docs/SRS/SRS.pdf}{Software
Requirements Specification (SRS)} document for the list of symbols,
abbreviations, and acronyms.


In addition, the following abbreviations are used in this document:\\

\renewcommand{\arraystretch}{1.2}
\begin{table}[h!]
\caption{Symbols, Abbreviations, and Acronyms}
\begin{tabularx}{\textwidth}{l l}
  \toprule		
  \textbf{symbol} & \textbf{description}\\
  \midrule 
  V\&V & Verification and Validation\\
  UI & User Interface\\
  OCR & Optical Character Recognition\\
  SQL & Structured Query Language\\
  GDPR & General Data Protection Regulation\\
  \bottomrule
\end{tabularx}
\end{table}

\newpage

\tableofcontents

\listoftables %if appropriate

\listoffigures %if appropriate

\newpage

\pagenumbering{arabic}

This document reports the results of the Verification and Validation (V\&V)
process for the \progname software. The V\&V plan is documented in the
\href{https://github.com/PlutosCapstone/Plutos/blob/main/docs/VnVPlan/VnVPlan.pdf}{Verification
and Validation Plan} document. 

\section{Functional Requirements Evaluation}

The functional system tests can be found in Section 4.1 of the
\href{https://github.com/PlutosCapstone/Plutos/blob/main/docs/VnVPlan/VnVPlan.pdf}{Verification
and Validation Plan} document. These tests are all performed manually.

\begin{table}[h!]
\centering
\caption{Functional Requirements Evaluation}
\begin{tabularx}{\textwidth}{>{\centering\arraybackslash}X >{\centering\arraybackslash}X >{\centering\arraybackslash}X}
  \toprule
  \textbf{Test ID} & \textbf{Pass/Fail} & \textbf{Comments} \\
  \midrule
  test-UAM-1 & Pass &  \\
  test-UAM-2 & Pass &  \\
  test-UAM-3 & Pass &  \\
  test-UAM-4 & Fail & Not yet implemented \\
  test-UAM-5 & Pass &  \\
  test-UAM-6 & Pass &  \\
  \midrule
  test-IP-1 & Pass & \\
  test-IP-2 & Pass & \\
  test-IP-3 & Fail & Not yet implemented \\
  \midrule
  test-MIS-1 & Pass & \\
  \midrule
  test-DM-1 & Pass & \\
  test-DM-2 & Pass & \\
  \midrule
  test-RS-1 & Pass & \\
  test-RS-2 & Pass & \\
  test-RS-3 & Pass & \\
  \midrule
  test-FT-1 & Fail & Not yet implemented \\
  test-FT-2 & Pass & \\
  test-FT-3 & Fail & Not yet implemented \\
  \bottomrule
\end{tabularx}
\end{table}


\section{Nonfunctional Requirements Evaluation}

The nonfunctional system tests can be found in Section 4.2 of the
\href{https://github.com/PlutosCapstone/Plutos/blob/main/docs/VnVPlan/VnVPlan.pdf}{Verification
and Validation Plan} document. Tests without comments are performed as described
in the plan.


\begin{longtable}{>{\centering\arraybackslash}p{0.2\textwidth} >{\centering\arraybackslash}p{0.2\textwidth} >{\centering\arraybackslash}p{0.5\textwidth}}
  \caption{Nonfunctional Requirements Evaluation}\\
    \toprule
    \textbf{Test ID} & \textbf{Pass/Fail} & \textbf{Comments} \\
    \midrule
    test-ACC-1 & Pass &
    \href{https://github.com/PlutosCapstone/Plutos/tree/main/src/server/tests/imageProcessing/data/categorization/receipt_items_output.csv}{Actual
    output}; accuracy is 47/57 = 82.46\%, which meets the threshold of 80\%. \\
    test-ACC-2 & Pass & By manually comparing the input
    \href{https://github.com/PlutosCapstone/Plutos/tree/main/src/server/tests/imageProcessing/data/parsing/input}{
    (set of receipt images)} with the
    \href{https://github.com/PlutosCapstone/Plutos/tree/main/src/server/tests/imageProcessing/data/parsing/input}{resulting
    output}, and calculating the accuracy as descripted in the V\&V Plan,
    current accuracy is ~80\%, which meets the threshold of 80\%.
    \begin{itemize}
      \item \textit{foodbasics\_1.jpg}: 13.5/15 = 90\%
      \item \textit{foodbasics\_2.jpg}: 7/9 = 77.78\%
      \item \textit{walmart\_1.jpg}: 7/10 = 70\%
      \item \textit{costco\_1.jpg}: 18.5/23 = 76.09\%
      \item Overall accuracy: 46/57 = 80.70\%
    \end{itemize}\\
    test-ACC-3 & Pass &  \\
    test-ACC-4 & Pass &  \\
    test-ACC-5 & Pass &  \\
    \midrule
    test-PERF-1 & Pass &  \\
    test-PERF-2 & Pass &  \\
    test-PERF-3 & Fail & Load testing has not yet been performed \\
    \midrule
    test-USAB-1 & Pass &  \\
    test-USAB-2 & Pass &  \\
    test-USAB-3 & Pass &  \\
    test-USAB-4 & Pass &  \\
    \midrule
    test-SEC-1 & Pass &  \\
    \midrule
    test-MTB-1 & Pass & System stability has been tested, but application is not
    backward compatible since it is still under active development. \\
    test-MTB-2 & Pass &  \\
    test-MTB-3 & Pass &  \\
    \midrule
    test-PORT-1 & Pass &  \\
    test-PORT-2 & Pass &  \\
    test-PORT-3 & Pass &  \\
    \midrule
    test-REUS-1 & Pass &  \\
    test-REUS-2 & Pass &  \\
    \midrule
    test-UND-1 & Pass &  \\
    test-UND-2 & Pass &  \\
    test-UND-3 & Pass &  \\
    \midrule
    test-LEGAL-1 & Fail & The application is still under active development, so
    it is still using the testing environment and not all security features are
    active. \\
    \bottomrule
\end{longtable}


	
\section{Comparison to Existing Implementation}	

This section will not be appropriate for every project.

\section{Unit Testing}

\subsection{Front-end unit tests}

All front-end unit tests can be found in the \href{https://github.com/PlutosCapstone/Plutos/tree/main/src/client/tests}{test directory}\\
Refer to Table \ref{tab:unit-testing} for unit test traceability table

\begin{table}[h]
  \centering
  \renewcommand{\arraystretch}{1.3}
  \begin{tabular}{| m{5cm} | m{8cm} |}
      \hline
      \textbf{Test} & \textbf{Testing plan} \\
      \hline
      test-UAM-1: Account creation &  \\
      \hline
      test-UAM-2: User login &  \\
      \hline
      test-UAM-3: User logout &  \\
      \hline
      test-UAM-4: Account update &  \\
      \hline
      test-UAM-5: Authorization access &  \\
      \hline
      test-UAM-6: Password reset & Manual testing \\
      \hline
      test-IP-1: Image upload & Manual testing \\
      \hline
      test-IP-2: Image preview &  \\
      \hline
      test-IP-3: Image upload file size limit &  \\
      \hline
      test-MIS-1: Manual input expense & AddExpenseView.test.tsx, AddExpenseModal.test.tsx \\
      \hline
      test-FT-1: View spending history and trends & ExpensesList.test.tsx, HomePageMetricsBox.test.tsx, SpendingDetails.test.tsx \\
      \hline
      test-FT-2: Set and track budget & BudgetBoxDetails.test.tsx, MyBudgetsBox.test.tsx, NewBudgetModal.test.tsx \\
      \hline
      test-FT-3: Notification when user approaching limit & Not implemented \\
      \hline
  \end{tabular}
  \caption{Unit Testing Table} \label{tab:unit-testing}
\end{table}


\section{Changes Due to Testing}

\wss{This section should highlight how feedback from the users and from 
the supervisor (when one exists) shaped the final product.  In particular 
the feedback from the Rev 0 demo to the supervisor (or to potential users) 
should be highlighted.}

\section{Automated Testing}
		
\section{Trace to Requirements}
		
\section{Trace to Modules}		

\section{Code Coverage Metrics}

\bibliographystyle{plainnat}
\bibliography{../../refs/References}

\newpage{}
\section*{Appendix --- Reflection}

The information in this section will be used to evaluate the team members on the
graduate attribute of Reflection.

\input{../Reflection.tex}

\begin{enumerate}
  \item What went well while writing this deliverable? 
  \item What pain points did you experience during this deliverable, and how
    did you resolve them?
  \item Which parts of this document stemmed from speaking to your client(s) or
  a proxy (e.g. your peers)? Which ones were not, and why?
  \item In what ways was the Verification and Validation (VnV) Plan different
  from the activities that were actually conducted for VnV?  If there were
  differences, what changes required the modification in the plan?  Why did
  these changes occur?  Would you be able to anticipate these changes in future
  projects?  If there weren't any differences, how was your team able to clearly
  predict a feasible amount of effort and the right tasks needed to build the
  evidence that demonstrates the required quality?  (It is expected that most
  teams will have had to deviate from their original VnV Plan.)
\end{enumerate}

\end{document}